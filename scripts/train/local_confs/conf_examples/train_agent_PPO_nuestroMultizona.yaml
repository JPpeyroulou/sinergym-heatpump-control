# ---------------------------------------------------------------------------- #
#                                    BASICS                                    #
# ---------------------------------------------------------------------------- #
experiment_name: Eplus-PPO-training-nuestroMultizona
environment: Eplus-nuestroMultizonaPPO-uru-continuous-v1
episodes: 60

# ---------------------------------------------------------------------------- #
#                                 SB3 ALGORITHM                                #
# ---------------------------------------------------------------------------- #
algorithm:
  name: stable_baselines3:PPO
  log_interval: 1
  parameters:
    policy: MlpPolicy
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 256
    n_epochs: 20
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    clip_range_vf: null
    normalize_advantage: true
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_sde: false
    sde_sample_freq: -1
    rollout_buffer_class: null
    rollout_buffer_kwargs: null
    target_kl: null
    stats_window_size: 100
    tensorboard_log: null
    policy_kwargs: {net_arch: [256, 256]}
    verbose: 1
    seed: null
    device: auto
    _init_setup_model: true

# ---------------------------------------------------------------------------- #
#                             INITIAL STATE (MODEL)                            #
# ---------------------------------------------------------------------------- #

# -------------------------------- Local Path -------------------------------- #
# model: 
#   local_path: </path/to/model>

# ---------------------------- Google Bucket Path ---------------------------- #
# model: 
#   bucket_path: gs://<path_to_model_google_bucket>

# ----------------------------- WANDB model Path ----------------------------- #
# model:
#   project: test-project
#   entity: sail_ugr
#   artifact_name: PPO-nuestroMultizona
#   artifact_type: output
#   artifact_tag: v0
#   artifact_path: Sinergym_output/evaluation/
#   model_path: Sinergym_output/evaluation/best_model.zip

# ---------------------------------------------------------------------------- #
#                                  EVALUATION                                  #
# ---------------------------------------------------------------------------- #
evaluation:
  eval_freq: 1
  eval_length: 1

# ---------------------------------------------------------------------------- #
#                       ENVIRONMENT OVERWRITE PARAMETERS                       #
# ---------------------------------------------------------------------------- #
# Yaml file with environment configuration (Optional)
#env_yaml_config: null
## Environment deep update for parameters with dictionary type, it is used to overwrite the environment parameters default is True).
#env_deep_update: true
# In order to overwrite some parameters of the environment, you can use the following
#env_params:
#  seed: null
#  reward: sinergym.utils.rewards:LinearReward
# ... other environment parameters



# ---------------------------------------------------------------------------- #
#                              WRAPPERS DEFINITION                             #
# ---------------------------------------------------------------------------- #
# Yaml file with wrappers configuration (Optional)
wrappers_yaml_config: null
# This overwrite wrappers in wrappers_yaml_config if defined
wrappers:
  - sinergym.utils.wrappers:NormalizeAction: {}
  - sinergym.utils.wrappers:NormalizeObservation: {}
  - sinergym.utils.wrappers:LoggerWrapper:
      storage_class: sinergym.utils.logger:LoggerStorage
  - sinergym.utils.wrappers:CSVLogger: {}
  # - sinergym.utils.wrappers:WandBLogger:
  #     entity: alejandro-campoy
  #     project_name: test-project
#
## ---------------------------------------------------------------------------- #
# ##--------------------------------------------------------------------------- #
cloud: 
  remote_store: null # remote bucket name
  auto_delete: null
  ##   group_name: group-example
